{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208d4be3-07eb-4d71-8fe9-67872ff97817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import threading\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchattacks\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import time\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77bd8729-23ac-427f-bc7b-bf55830be2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox import TensorFlowModel, accuracy, samples, Model\n",
    "import eagerpy as ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6fa4ab1-4a9d-423a-94d2-fb19e16dfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4fd56b-cfd1-4bd8-a80e-d7b3e012a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustbench.utils import clean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8490118-8237-4a64-ac0c-7e6f8ab77f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self, tau=None, beta=None, spike_grad=None, model_type='QIF'):\n",
    "        super(SNN, self).__init__()\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        # Define the common layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(28 * 28, 10, bias=False)\n",
    "\n",
    "        # Add the appropriate spiking neuron to the layer based on the model type\n",
    "        if model_type == 'QIF':\n",
    "            self.layer = nn.Sequential(\n",
    "                self.flatten,\n",
    "                self.fc,\n",
    "                neuron.QIFNode(tau=tau)\n",
    "            )\n",
    "        elif model_type == 'Izhikevich':\n",
    "            self.layer = nn.Sequential(\n",
    "                self.flatten,\n",
    "                self.fc,\n",
    "                neuron.IzhikevichNode(tau=tau)\n",
    "            )\n",
    "        elif model_type == 'LIF':\n",
    "            self.snn1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if self.model_type == 'LIF':\n",
    "            return self.forward_leaky(x)\n",
    "        else:\n",
    "            return self.layer(x)\n",
    "\n",
    "    def forward_leaky(self, x):\n",
    "        # Flatten and apply linear transformation\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Initialize and reset membrane potential\n",
    "        mem1 = self.snn1.reset_mem()\n",
    "        spk1, mem1 = self.snn1(x, mem1)\n",
    "        return spk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e586be98-deeb-4d0b-b1b7-376dc619415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to start training\n",
    "def start_training():\n",
    "    # Create the args dictionary\n",
    "    args = {\n",
    "        'model': model_var.get(),\n",
    "        'attack': attack_var.get(),\n",
    "        'eps': float(epsilon_var.get().split('/')[0]) / 225,  # Convert fraction to float\n",
    "        'epochs': int(epochs_var.get()),\n",
    "        'lr': 1e-2,  # Keep learning rate fixed\n",
    "        'b': int(batch_size_var.get()),\n",
    "        'tau': 2.0,  # Fixed tau value\n",
    "        'beta': 0.6, #fixed\n",
    "        'T': int(timesteps_var.get()),  # Get T from the user input\n",
    "        'device': 'cpu',  # or 'cuda' if GPU is available\n",
    "        'data_dir': './mnist_data',\n",
    "        'out_dir': './results',\n",
    "        'resume': None,\n",
    "        'amp': False,  # Disable AMP since using CPU\n",
    "        'opt': 'adam',  # Fixed optimizer\n",
    "        'momentum': 0.9,\n",
    "        'j': 2,  # Number of workers for data loading\n",
    "        'dim': float (pixels_var.get()) # Size of patch, in %, for Pixle attack\n",
    "    }\n",
    "\n",
    "    # Run the training in a separate thread to keep the GUI responsive\n",
    "    threading.Thread(target=train_and_evaluate, args=(args,)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a98a346-0bf3-4313-b679-9190fbe8a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "@torch.no_grad()\n",
    "def get_accuracy(model, data_loader, atk=None, n_limit=1e10, device=None):\n",
    "    model = model.eval()\n",
    "\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in data_loader:\n",
    "        X = images.to(device)\n",
    "        Y = labels.to(device)\n",
    "\n",
    "        if atk:\n",
    "            X = atk(X, Y)\n",
    "\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += predicted.size(0)\n",
    "        correct += (predicted == Y).sum().item()\n",
    "\n",
    "        if total > n_limit:\n",
    "            break\n",
    "\n",
    "    return 100 * float(correct) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "392ad960-1343-4b1b-9a49-c90be8710f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(args):\n",
    "    # Check the model type and initialize accordingly\n",
    "    if args['model'] == 'LIF':\n",
    "        net = SNN(beta=args['beta'], spike_grad=surrogate.fast_sigmoid(slope=25), model_type='LIF')\n",
    "    else:\n",
    "        net = SNN(tau=args['tau'], model_type=args['model'])\n",
    "    \n",
    "    # Move the model to the specified device (CPU or GPU)\n",
    "    device = torch.device(args['device'])\n",
    "    net.to(device)\n",
    "\n",
    "    # Load datasets\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0,), (1,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST(\n",
    "        root=args['data_dir'],\n",
    "        train=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "        download=False\n",
    "    )\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root=args['data_dir'],\n",
    "        train=False,\n",
    "        transform=transforms.ToTensor(),\n",
    "        download=False\n",
    "    )\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=args['b'],\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=args['j'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=args['b'],\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=args['j'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # AMP setup and optimizer\n",
    "    scaler = None\n",
    "    start_epoch = 0\n",
    "    max_test_acc = -1\n",
    "    optimizer = optim.Adam(net.parameters(), lr=args['lr'])\n",
    "\n",
    "    # Resume from checkpoint if provided\n",
    "    if args['resume']:\n",
    "        checkpoint = torch.load(args['resume'], map_location='cpu')\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        max_test_acc = checkpoint['max_test_acc']\n",
    "\n",
    "    # Output directory setup\n",
    "    out_dir = os.path.join(args['out_dir'], f\"T{args['T']}_b{args['b']}_{args['opt']}_lr{args['lr']}\")\n",
    "    if args['amp']:\n",
    "        out_dir += '_amp'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "        args_txt.write(str(args))\n",
    "\n",
    "    writer = SummaryWriter(out_dir, purge_step=start_epoch)\n",
    "    encoder = encoding.PoissonEncoder()\n",
    "\n",
    "    # Training and evaluation loop\n",
    "    for epoch in range(start_epoch, args['epochs']):\n",
    "        start_time = time.time()\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_samples = 0\n",
    "\n",
    "        for img, label in tqdm(train_data_loader, desc=\"Training\", unit=\"batch\"):\n",
    "            optimizer.zero_grad()\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            label_onehot = F.one_hot(label, 10).float()\n",
    "\n",
    "            out_fr = 0\n",
    "            for t in range(args['T']):\n",
    "                encoded_img = encoder(img)\n",
    "                out_fr += net(encoded_img)\n",
    "                \n",
    "            out_fr /= args['T']\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_samples += label.numel()\n",
    "            train_loss += loss.item() * label.numel()\n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "            if args['model'] != 'LIF':\n",
    "                functional.reset_net(net)\n",
    "\n",
    "        train_loss /= train_samples\n",
    "        train_acc /= train_samples\n",
    "        writer.add_scalar('train_loss', train_loss, epoch)\n",
    "        writer.add_scalar('train_acc', train_acc, epoch)\n",
    "\n",
    "        # Testing phase with tqdm\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        test_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for img, label in tqdm(test_data_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "                img = img.to(device)\n",
    "                label = label.to(device)\n",
    "                label_onehot = F.one_hot(label, 10).float()\n",
    "                out_fr = 0.\n",
    "                \n",
    "                for t in range(args['T']):\n",
    "                    encoded_img = encoder(img)\n",
    "                    out_fr += net(encoded_img)\n",
    "                out_fr /= args['T']\n",
    "                loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "                test_samples += label.numel()\n",
    "                test_loss += loss.item() * label.numel()\n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "                \n",
    "                if args['model'] != 'LIF':\n",
    "                    functional.reset_net(net)\n",
    "                \n",
    "        test_loss /= test_samples\n",
    "        test_acc /= test_samples\n",
    "        writer.add_scalar('test_loss', test_loss, epoch)\n",
    "        writer.add_scalar('test_acc', test_acc, epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_max = False\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            save_max = True\n",
    "\n",
    "        checkpoint = {\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'max_test_acc': max_test_acc\n",
    "        }\n",
    "\n",
    "        if save_max:\n",
    "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_latest.pth'))\n",
    "\n",
    "        # Print results\n",
    "        print(f'epoch = {epoch}, train_loss = {train_loss:.4f}, train_acc = {train_acc:.4f}, test_loss = {test_loss:.4f}, test_acc = {test_acc:.4f}, max_test_acc = {max_test_acc:.4f}')\n",
    "\n",
    "    # Adversarial accuracy evaluation using the updated approach\n",
    "    if args['attack'] == 'PGD':\n",
    "        attack = attack = torchattacks.PGD(net, eps=args['eps'], alpha=2/255, steps=10, random_start=True)\n",
    "    elif args['attack'] == 'FGSM':\n",
    "        attack = torchattacks.FGSM(net, eps=args['eps'])\n",
    "    else: \n",
    "        attack = torchattacks.Pixle(model=net,x_dimensions=args['dim'],y_dimensions=args['dim'])\n",
    "\n",
    "    \n",
    "    attack.set_mode_targeted_by_label()\n",
    "\n",
    "    \n",
    "    # Define a transform\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "    dataset = torchvision.datasets.MNIST(\n",
    "    root=args['data_dir'],\n",
    "    transform=transform)\n",
    "\n",
    "    data_loader = data.DataLoader(dataset, batch_size=args['b'], shuffle=False, drop_last=False, num_workers=2)\n",
    "    \n",
    "    # Perform adversarial attack\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    new_labels = (labels + 1) % 10 # New labels\n",
    "\n",
    "    adv_images = attack(images, new_labels)\n",
    "\n",
    "    # Calculate clean accuracy\n",
    "    #clean_acc = get_accuracy(net, data_loader, device=device)\n",
    "    clean_acc = clean_accuracy(net, images, labels)\n",
    "    \n",
    "    # Calculate adversarial accuracy\n",
    "    with torch.no_grad():\n",
    "        outputs = net(adv_images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        adv_acc1 = correct / labels.size(0)\n",
    "\n",
    "    adv_acc2 = clean_accuracy(net, adv_images, labels)\n",
    "\n",
    "    print(f'Model Choice: {args['model']}')\n",
    "    print(f'Attack Choice: {args['attack']}')\n",
    "    print(f'Clean Accuracy: {clean_acc * 100:.2f}%')\n",
    "    print(f'Robust Accuracy1: {adv_acc1 * 100:.2f}%')\n",
    "    print(f'Robust Accuracy2: {adv_acc2 * 100:.2f}%')\n",
    "    print(f'Accuracy Degradation: {(clean_acc - adv_acc2) * 100:.2f}%')\n",
    "    print(f'Time Steps: {args['T']}')\n",
    "    print(f'Epsilon x 225: {args['eps'] * 225}')\n",
    "    \n",
    "    if args['attack'] == 'Pixle':\n",
    "        print(f'(Pixle) Size of Patch: {args['dim'] * 100:.2f}%')\n",
    "\n",
    "\n",
    "    with open(os.path.join(out_dir, 'accuracies.txt'), 'w') as f:\n",
    "        f.write(f'Clean Accuracy: {clean_acc * 100:.2f}%\\n')\n",
    "        f.write(f'Adversarial Accuracy1: {adv_acc1 * 100:.2f}%\\n')\n",
    "        f.write(f'Adversarial Accuracy1: {adv_acc1 * 100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fef73be-ea35-4b17-8299-72c5930f889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tkinter UI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"(T) SNN Training App\")\n",
    "\n",
    "# Model selection\n",
    "ttk.Label(root, text=\"Select Model:\").grid(row=0, column=0, padx=10, pady=10)\n",
    "model_var = tk.StringVar(value=\"QIF\")\n",
    "model_dropdown = ttk.Combobox(root, textvariable=model_var, values=[\"QIF\", \"Izhikevich\", \"LIF\"])\n",
    "model_dropdown.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "# Attack selection\n",
    "ttk.Label(root, text=\"Select Attack:\").grid(row=1, column=0, padx=10, pady=10)\n",
    "attack_var = tk.StringVar(value=\"PGD\")\n",
    "attack_dropdown = ttk.Combobox(root, textvariable=attack_var, values=[\"PGD\", \"FGSM\", \"Pixle\"])\n",
    "attack_dropdown.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "# Epsilon selection (fractions of 2k/225)\n",
    "ttk.Label(root, text=\"Select Epsilon:\").grid(row=2, column=0, padx=10, pady=10)\n",
    "epsilon_var = tk.StringVar(value=\"8/225\")\n",
    "epsilon_dropdown = ttk.Combobox(root, textvariable=epsilon_var, values=[f'{2*k}/225' for k in [4, 8, 16, 32]])\n",
    "epsilon_dropdown.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "epochs_var = tk.StringVar(value=\"1\")\n",
    "batch_size_var = tk.StringVar(value=\"16\") #Batch Size stays at 16\n",
    "\n",
    "# Timesteps (T) entry\n",
    "ttk.Label(root, text=\"Timesteps (T):\").grid(row=5, column=0, padx=10, pady=10)\n",
    "timesteps_var = tk.StringVar(value=\"15\")\n",
    "timesteps_entry = ttk.Entry(root, textvariable=timesteps_var)\n",
    "timesteps_entry.grid(row=5, column=1, padx=10, pady=10)\n",
    "\n",
    "# Pixle Attack entry\n",
    "ttk.Label(root, text=\"(For Pixle Attack): Size of patch:\").grid(row=6, column=0, padx=10, pady=10)\n",
    "value_mapping = {f\"{i}%\": f\"{i / 100:.2f}\" for i in range(10, 105, 10)}\n",
    "pixels_var = tk.StringVar(value=\"0.1\")\n",
    "pixels_combobox = ttk.Combobox(\n",
    "    root,\n",
    "    textvariable=pixels_var,\n",
    "    values=list(value_mapping.keys()),\n",
    "    state=\"readonly\"\n",
    ")\n",
    "pixels_combobox.grid(row=6, column=1, padx=10, pady=10)\n",
    "\n",
    "# Bind the combobox selection event to the update function\n",
    "pixels_combobox.bind(\"<<ComboboxSelected>>\", lambda event: pixels_var.set(value_mapping[pixels_combobox.get()]))\n",
    "\n",
    "# Start button\n",
    "start_button = ttk.Button(root, text=\"Start Training\", command=start_training)\n",
    "start_button.grid(row=7, columnspan=2, padx=10, pady=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed50964f-b6d9-4077-8e19-288892aa47c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 3750/3750 [00:50<00:00, 73.99batch/s]\n",
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 625/625 [00:08<00:00, 74.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, train_loss = 0.0394, train_acc = 0.7931, test_loss = 0.0491, test_acc = 0.7443, max_test_acc = 0.7443\n",
      "Attack mode is changed to 'targeted(label)'.\n",
      "Model Choice: Izhikevich\n",
      "Attack Choice: Pixle\n",
      "Clean Accuracy: 81.25%\n",
      "Robust Accuracy1: 12.50%\n",
      "Robust Accuracy2: 25.00%\n",
      "Accuracy Degradation: 56.25%\n",
      "Time Steps: 15\n",
      "Epsilon x 225: 8.0\n",
      "(Pixle) Size of Patch: 20.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 3750/3750 [00:51<00:00, 72.14batch/s]\n",
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 625/625 [00:08<00:00, 75.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, train_loss = 0.0330, train_acc = 0.8318, test_loss = 0.0332, test_acc = 0.8384, max_test_acc = 0.8384\n",
      "Attack mode is changed to 'targeted(label)'.\n",
      "Model Choice: Izhikevich\n",
      "Attack Choice: Pixle\n",
      "Clean Accuracy: 81.25%\n",
      "Robust Accuracy1: 6.25%\n",
      "Robust Accuracy2: 12.50%\n",
      "Accuracy Degradation: 68.75%\n",
      "Time Steps: 15\n",
      "Epsilon x 225: 8.0\n",
      "(Pixle) Size of Patch: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████| 3750/3750 [00:52<00:00, 72.01batch/s]\n",
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 625/625 [00:08<00:00, 75.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, train_loss = 0.0321, train_acc = 0.8336, test_loss = 0.0262, test_acc = 0.8595, max_test_acc = 0.8595\n",
      "Attack mode is changed to 'targeted(label)'.\n",
      "Model Choice: Izhikevich\n",
      "Attack Choice: Pixle\n",
      "Clean Accuracy: 81.25%\n",
      "Robust Accuracy1: 0.00%\n",
      "Robust Accuracy2: 6.25%\n",
      "Accuracy Degradation: 75.00%\n",
      "Time Steps: 15\n",
      "Epsilon x 225: 8.0\n",
      "(Pixle) Size of Patch: 60.00%\n"
     ]
    }
   ],
   "source": [
    "# Run the application\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
